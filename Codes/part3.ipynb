{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8662ec56-f23e-468d-94fe-7fa1d2a51459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "import pickle\n",
    "import os\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90e0366-385b-4928-8e64-afe69a5fb7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the used device\n",
    "# Check whether cuda or cpu is used\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# If GPU is used, write cuda. Otherwise, CPU will be used for training\n",
    "print(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d3b4bf-6147-4d20-8958-2f8aa3b479ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
    "    torchvision.transforms.Grayscale()\n",
    "])\n",
    "\n",
    "# Training set\n",
    "train_data = torchvision.datasets.CIFAR10(\"./data\", train = True, download = True,\n",
    "                                          transform = transform)\n",
    "# Test set\n",
    "test_data = torchvision.datasets.CIFAR10(\"./data\", train = False,\n",
    "                                         transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6348dca2-3a6d-4981-837f-d692b04c80ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation set that includes 10% of the training set\n",
    "# So, firstly we should check the number of samples in the training set\n",
    "train_length = len(train_data)\n",
    "\n",
    "# Create a numpy array that stores the indices of train set from 0 to train_length\n",
    "# In other words, [0, 50000)\n",
    "train_indices = np.arange((train_length))\n",
    "\n",
    "# Locate classes of each index so that they can be splitted equally\n",
    "class_labels = np.array(train_data.targets)\n",
    "\n",
    "# Take the 10% of the train set and store it as validation set length\n",
    "validation_length = int(train_length*0.1)\n",
    "\n",
    "# Number of samples per each class\n",
    "class_sample_number = int(validation_length / len(train_data.classes))\n",
    "\n",
    "# Create a list includes indices of each class\n",
    "class_indices = [np.where(class_labels == i)[0] for i in range(len(train_data.classes))]\n",
    "\n",
    "# Initialize the indices of the validation set\n",
    "validation_indices = []\n",
    "\n",
    "# Randomly chose indices per each class equally from the training set\n",
    "for index in class_indices:\n",
    "  validation_indices.extend(np.random.choice(index, class_sample_number, replace = False))\n",
    "\n",
    "# Calculate the train indices after the validation split\n",
    "train_indices = list(set(train_indices) - set(validation_indices))\n",
    "\n",
    "# Create a train sampler by excluding indices that are separated for the validation set\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "\n",
    "# Create a validation sampler by using the validation indices calculated\n",
    "validation_sampler = SubsetRandomSampler(validation_indices) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6e8cd0b-a322-4a44-85e2-938a93ed3e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataloaders to that are sampled accordingly\n",
    "batch_size = 50\n",
    "train_generator = torch.utils.data.DataLoader(train_data, batch_size = batch_size, sampler = train_sampler)\n",
    "test_generator = torch.utils.data.DataLoader(test_data, batch_size = batch_size)\n",
    "validation_generator =  torch.utils.data.DataLoader(train_data, batch_size = batch_size, sampler = validation_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de0cd087-92c5-44c8-b5f8-f6b1cefafe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether the train, test and validation generators are created correctly\n",
    "# In the beginning, the sizes of the datasets were as follows:\n",
    "# Train Set: 50000\n",
    "# Test Set : 10000\n",
    "# Validation Set: 0\n",
    "\n",
    "# After splitting 10% of the training set into validation set, these datasets are obtained:\n",
    "# Train Set: 45000\n",
    "# Test Set : 10000\n",
    "# Validation Set: 5000\n",
    "\n",
    "# According to the new values, the outputs of the DataLoaders should be as follows:\n",
    "# train_generator: 45000 / 50 = 900\n",
    "# test_generator : 10000 / 50 = 200\n",
    "# validation_generator: 5000 / 50 = 100\n",
    "# Where first operand is the number of images per each dataset, and the second operand is the batch size\n",
    "\n",
    "# So, this assert tests whether the DataLoaders created correctly or not\n",
    "assert( (len(train_generator) == 900) & (len(test_generator) == 200)  & (len(validation_generator) == 100) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bc310e1-53ee-4f3a-8178-e0a22d196e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General definitions about the architectures:\n",
    "# FC-N: Fully Connected layer of size N\n",
    "# Conv-WxHxN: N Convolutional layers of size WxH\n",
    "# MaxPool-2x2: Max-pooling operation of pool size 2x2\n",
    "# PredictionLayer: FC-10\n",
    "\n",
    "# Parameter Definitons:\n",
    "# Stride: 1 for Convolutions\n",
    "# Stride: 2 for Max-pooling operations\n",
    "\n",
    "# Padding: Should be valid for both Convolution and Max-pooling operations\n",
    "\n",
    "# Optimizer: Adam (Adaptive Moment Estimation) with default setting\n",
    "# Adam Optimizer with default settings:\n",
    "# torch.optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0,\n",
    "#                  amsgrad=False, *, foreach=None, maximize=False, capturable=False, \n",
    "#                  differentiable=False, fused=None)\n",
    "\n",
    "# Batch Size: 50 samples\n",
    "\n",
    "# Three Dataset: Train Set, Test Set and Validation Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e97b1d1b-5b5f-4481-8512-45160bca9a13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First Class: Multi Layer Perceptron 1 Class \n",
    "# mlp1: [FC-32, ReLU] + PredictionLayer\n",
    "class mlp1(torch.nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, num_classes):\n",
    "    super(mlp1, self).__init__()\n",
    "    self.input_size = input_size\n",
    "    self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
    "    self.fc2 = torch.nn.Linear(hidden_size, num_classes, bias = False)\n",
    "    self.relu = torch.nn.ReLU()\n",
    "  def forward(self, x):\n",
    "    x = x.view(-1, self.input_size)\n",
    "    hidden = self.fc1(x)\n",
    "    relu = self.relu(hidden)\n",
    "    output = self.fc2(relu)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2625e94a-ece9-4522-8e47-a819cc010a3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Second Class: Multi Layer Perceptron 2 Class\n",
    "class mlp2(torch.nn.Module):\n",
    "  def __init__(self, input_size, hidden_size1, hidden_size2, num_classes):\n",
    "    super(mlp2, self).__init__()\n",
    "    self.input_size = input_size\n",
    "    self.fc1 = torch.nn.Linear(input_size, hidden_size1)\n",
    "    self.fc2 = torch.nn.Linear(hidden_size1, hidden_size2, bias = False)\n",
    "    self.fc3 = torch.nn.Linear(hidden_size2, num_classes, bias = False)\n",
    "    self.relu = torch.nn.ReLU()\n",
    "  def forward(self, x):\n",
    "    x = x.view(-1, self.input_size)\n",
    "    hidden1 = self.fc1(x)\n",
    "    relu1 = self.relu(hidden1)\n",
    "    hidden2 = self.fc2(relu1)\n",
    "    relu2 = self.relu(hidden2)\n",
    "    output = self.fc3(relu2)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dd6bee9-2c46-4d29-a241-e0cb46356261",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Third Class: Convolutional Neural Network 3\n",
    "class cnn_3(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(cnn_3, self).__init__()\n",
    "    self.conv1 = torch.nn.Conv2d(1, 16, kernel_size = (3,3), stride = 1, padding = 'valid')\n",
    "    self.relu1 = torch.nn.ReLU()\n",
    "    self.conv2 = torch.nn.Conv2d(16, 8, kernel_size = (5,5), stride = 1, padding = 'valid')\n",
    "    self.relu2 = torch.nn.ReLU()\n",
    "    self.maxpool1 = torch.nn.MaxPool2d(kernel_size = (2,2), stride = 2, padding = 0)\n",
    "    self.conv3 = torch.nn.Conv2d(8, 16, kernel_size = (7,7), stride = 1, padding = 'valid')\n",
    "    self.maxpool2 = torch.nn.MaxPool2d(kernel_size = (2,2), stride = 2, padding = 0)\n",
    "    self.fc  = torch.nn.Linear(16*3*3, 10, bias = False)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.relu1(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.relu2(x)\n",
    "    x = self.maxpool1(x)\n",
    "    x = self.conv3(x)\n",
    "    x = self.maxpool2(x)\n",
    "    x = x.view(-1, 16*3*3)\n",
    "    \n",
    "    x = self.fc(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb2966f7-c5f7-4626-8cc8-f280907a91a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fourth Class: Convolutional Neural Network 4\n",
    "class cnn_4(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(cnn_4, self).__init__()\n",
    "    self.conv1 = torch.nn.Conv2d(1, 16, kernel_size = (3,3), stride = 1, padding = 'valid')\n",
    "    self.relu1 = torch.nn.ReLU()\n",
    "    self.conv2 = torch.nn.Conv2d(16, 8, kernel_size = (3,3), stride = 1, padding = 'valid')\n",
    "    self.relu2 = torch.nn.ReLU()\n",
    "    self.conv3 = torch.nn.Conv2d(8, 16, kernel_size = (5,5), stride = 1, padding = 'valid')\n",
    "    self.relu3 = torch.nn.ReLU()\n",
    "    self.maxpool1 = torch.nn.MaxPool2d(kernel_size = (2,2), stride = 2, padding = 0)\n",
    "    self.conv4 = torch.nn.Conv2d(16, 16, kernel_size = (5,5), stride = 1, padding = 'valid')\n",
    "    self.relu4 = torch.nn.ReLU()\n",
    "    self.maxpool2 = torch.nn.MaxPool2d(kernel_size = (2,2), stride = 2, padding = 0)\n",
    "    self.fc = torch.nn.Linear(16*4*4, 10, bias = False)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.relu1(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.relu2(x)\n",
    "    x = self.conv3(x)\n",
    "    x = self.relu3(x)\n",
    "    x = self.maxpool1(x)\n",
    "    x = self.conv4(x)\n",
    "    x = self.relu4(x)\n",
    "    x = self.maxpool2(x)\n",
    "    x = x.view(-1, 16*4*4)\n",
    "    x = self.fc(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5349937-f314-46f4-9ab7-864272a79eb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fifth Class: Convolutional Neural Network 5\n",
    "class cnn_5(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(cnn_5, self).__init__()\n",
    "    self.conv1 = torch.nn.Conv2d(1, 8, kernel_size = (3,3), stride = 1, padding = 'valid')\n",
    "    self.relu1 = torch.nn.ReLU()\n",
    "    self.conv2 = torch.nn.Conv2d(8, 16, kernel_size = (3,3), stride = 1, padding = 'valid')\n",
    "    self.relu2 = torch.nn.ReLU()\n",
    "    self.conv3 = torch.nn.Conv2d(16, 8, kernel_size = (3,3), stride = 1, padding = 'valid')\n",
    "    self.relu3 = torch.nn.ReLU()\n",
    "    self.conv4 = torch.nn.Conv2d(8, 16, kernel_size = (3,3), stride = 1, padding = 'valid')\n",
    "    self.relu4 = torch.nn.ReLU()\n",
    "    self.maxpool1 = torch.nn.MaxPool2d(kernel_size = (2,2), stride = 2, padding = 0)\n",
    "    self.conv5 = torch.nn.Conv2d(16, 16, kernel_size = (3,3), stride = 1, padding = 'valid')\n",
    "    self.relu5 = torch.nn.ReLU()\n",
    "    self.conv6 = torch.nn.Conv2d(16, 8, kernel_size = (3,3), stride = 1, padding = 'valid')\n",
    "    self.relu6 = torch.nn.ReLU()\n",
    "    self.maxpool2 = torch.nn.MaxPool2d(kernel_size = (2,2), stride = 2, padding = 0)\n",
    "    self.fc = torch.nn.Linear(16*4*4, 10, bias = False)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.relu1(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.relu2(x)\n",
    "    x = self.conv3(x)\n",
    "    x = self.relu3(x)\n",
    "    x = self.maxpool1(x)\n",
    "    x = self.conv4(x)\n",
    "    x = self.relu4(x)\n",
    "    x = self.conv5(x)\n",
    "    x = self.relu5(x)\n",
    "    x = self.maxpool2(x)\n",
    "    x = x.view(-1, 16*4*4)\n",
    "    x = self.fc(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bce1d2-8c0f-4deb-b177-ab3e79212164",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change the name of the model as required\n",
    "model = cnn_4()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ae5b497-f401-4c35-846b-94caccfd9e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If CNNs are used, type model.conv1. Otherwise, type model.fc1\n",
    "params_cnn_4 = model.conv1.weight.data.clone().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7544142-d9fd-440e-bcc4-a6dacd878fb8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Traing the model\n",
    "# Define the epoch number\n",
    "epoch = 15\n",
    "\n",
    "# Create train, validation and test accuracy lists that hold the accuracy values\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "validation_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "# Create average train, validation and test accuracy lists that hold the average of the accuracy values\n",
    "avg_loss_curve = []\n",
    "avg_train_acc_curve = []\n",
    "avg_val_acc_curve = []\n",
    "\n",
    "# Create variables that hold best model weights and best test accuracy\n",
    "best_weights = None\n",
    "best_test_acc = 0.0\n",
    "\n",
    "# Calculate the total number of batches from division of train set and batch size \n",
    "batch_number = int(len(train_generator.dataset)/batch_size)\n",
    "total_run = 10\n",
    "# Train and evaluate the model 10 times\n",
    "for iteration in range(total_run):\n",
    "\n",
    "  # Create loss: use cross entropy loss\n",
    "  loss_func = torch.nn.CrossEntropyLoss()\n",
    "  # Create the Adam optimizer with default parameters\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, betas = (0.9, 0.999), eps = 1e-08, weight_decay = 0)\n",
    "\n",
    "  # For loop that iterates for each epoch\n",
    "  for cur_epoch in range(epoch):\n",
    "    # Transfer the model to train mode\n",
    "    model.train()\n",
    "    for batch_idx, (x_train, y_train) in enumerate(train_generator):\n",
    "      # Transfer the input and the output to the used device (cpu or cuda)\n",
    "      x_train, y_train = x_train.to(device), y_train.to(device)\n",
    "\n",
    "      # At every iteration reset the gradient to zero so that start from scratch\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # Make prediction by using the model\n",
    "      y_prediction = model(x_train)\n",
    "\n",
    "      # Calculate the loss  \n",
    "      loss = loss_func(y_prediction, y_train)\n",
    "\n",
    "      # Backward pass and optimization step\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      if (batch_idx + 1) % 10 == 0:\n",
    "        # Save training loss for every 10 steps\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        # Transfer the model to eval mode\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "\n",
    "          # Calculate the training accuracy\n",
    "          # Initialize the correct and total predictions\n",
    "          correct_train = 0\n",
    "          total_train = 0\n",
    "\n",
    "          output = model(x_train)\n",
    "          y_prediction = output.argmax(dim=1)\n",
    "\n",
    "          for i in range(y_prediction.shape[0]):\n",
    "            if y_train[i] == y_prediction[i]:\n",
    "              correct_train += 1\n",
    "            total_train += 1\n",
    "          \n",
    "          # Append the train accuracy result to the list  \n",
    "          train_acc = 100 * correct_train / total_train\n",
    "          train_accuracy.append(train_acc)\n",
    "        \n",
    "        for x_validation, y_validation in validation_generator:\n",
    "          x_validation = x_validation.to(device)\n",
    "          y_validation = y_validation.to(device)\n",
    "\n",
    "          # Save validation accuracy for every 10 steps          \n",
    "          model.eval()\n",
    "          with torch.no_grad():\n",
    "\n",
    "            # Calculate the validation accuracy\n",
    "            # Initialize the correct and total predictions\n",
    "            correct_validation = 0\n",
    "            total_validation = 0\n",
    "\n",
    "            output = model(x_validation)\n",
    "            y_prediction = output.argmax(dim=1)\n",
    "\n",
    "            for i in range(y_prediction.shape[0]):\n",
    "              if y_validation[i] == y_prediction[i]:\n",
    "                correct_validation += 1\n",
    "              total_validation += 1\n",
    "\n",
    "            # Append the validation accuracy result to the list\n",
    "            validation_acc = 100 * correct_validation / total_validation\n",
    "            validation_accuracy.append(validation_acc)\n",
    "\n",
    "        print('Run [{}/{}], Epoch [{}/{}], Step [{}/{}], Training Acc: {:.2f}%, Validation Acc: {:.2f}%'\n",
    "                      .format(iteration+1, total_run, cur_epoch+1, epoch, batch_idx + 1, len(train_generator), train_acc, validation_acc))\n",
    "  # Calculate the test accuracy\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "\n",
    "    for x_test, y_test in test_generator:\n",
    "      x_test = x_test.to(device)\n",
    "      y_test = y_test.to(device)\n",
    "\n",
    "      output = model(x_test)\n",
    "      y_prediction = output.argmax(dim=1)\n",
    "\n",
    "      for i in range(y_prediction.shape[0]):\n",
    "        if y_test[i] == y_prediction[i]:\n",
    "          correct_test += 1\n",
    "        total_test += 1\n",
    "\n",
    "    # Append the result to the list\n",
    "    test_accuracy.append(100 * correct_test / total_test)\n",
    "\n",
    "    # Save the best test accuracy and best model weights\n",
    "    for test_idx in range(len(test_accuracy)):\n",
    "      if test_accuracy[test_idx] > best_test_acc:\n",
    "        best_test_acc = test_accuracy[test_idx]\n",
    "        best_weights = model.conv1.weight.data.clone().numpy()\n",
    "  \n",
    "  #best_test_acc.append(best_test_accucary)\n",
    "  avg_loss_curve.append(np.mean(train_loss, axis = 0))\n",
    "  avg_train_acc_curve.append(np.mean(train_accuracy, axis = 0))\n",
    "  avg_val_acc_curve.append(np.mean(validation_accuracy, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187f1b36-e816-480a-b499-22b8bbe41118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the difference between the initial weights and the best weights\n",
    "(best_weights - params_cnn_4).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2de3204-fe34-4f45-9d78-238cf3e1a550",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_result_dict = {\n",
    "    'name': 'cnn_4',\n",
    "    'loss_curve': avg_loss_curve,\n",
    "    'train_acc_curve': avg_train_acc_curve,\n",
    "    'val_acc_curve': avg_val_acc_curve,\n",
    "    'test_acc': best_test_acc,\n",
    "    'weights': best_weights\n",
    "}\n",
    "\n",
    "# Save the dictionary object to a file\n",
    "filename = 'part3_cnn_4.pkl'\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(train_result_dict, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e061b342",
   "metadata": {},
   "source": [
    "# Include part3Plots and visualizeWeights functions to continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406deef0-7373-4fab-a37c-4270088cc5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [train_result_dict]\n",
    "\n",
    "part3Plots(results, save_dir=r'C:/Users/Yasin', filename='part3Plots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f3fbc1-3130-4e0d-af89-d17e424c10a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = train_result_dict['weights']\n",
    "visualizeWeights(weights, save_dir='C:/Users/yasin', filename='input_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf245975-32d6-4353-b97d-c4541c0317e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = params_cnn_4\n",
    "visualizeWeights(weights, save_dir='C:/Users/yasin', filename='before_train_weights')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
